{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ce3136c-da41-4bc3-82d8-6300a62706f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+------+------------+--------------+-----------+------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n|Customer_ID|Age|Gender|  Occupation|Marital Status|Family Size|Income|Expenditure|Use Frequency|Loan Category|Loan Amount|Overdue| Debt Record| Returned Cheque| Dishonour of Bill|\n+-----------+---+------+------------+--------------+-----------+------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\n|    IB14001| 30|  MALE|BANK MANAGER|        SINGLE|          4| 50000|      22199|            6|      HOUSING| 10,00,000 |      5|      42,898|               6|                 9|\n|    IB14008| 44|  MALE|   PROFESSOR|       MARRIED|          6| 51000|      19999|            4|     SHOPPING|     50,000|      3|      33,999|               1|                 5|\n|    IB14012| 30|FEMALE|     DENTIST|        SINGLE|          3| 58450|      27675|            5|   TRAVELLING|     75,000|      6|      20,876|               3|                 1|\n|    IB14018| 29|  MALE|     TEACHER|       MARRIED|          5| 45767|      12787|            3|    GOLD LOAN|  6,00,000 |      7|      11,000|               0|                 4|\n|    IB14022| 34|  MALE|      POLICE|        SINGLE|          4| 43521|      11999|            3|   AUTOMOBILE|  2,00,000 |      2|      43,898|               1|                 2|\n+-----------+---+------+------------+--------------+-----------+------+-----------+-------------+-------------+-----------+-------+------------+----------------+------------------+\nonly showing top 5 rows\n\n+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+--------------+---------------+------+\n|RowNumber|CustomerId| Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|IsActiveMember|EstimatedSalary|Exited|\n+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+--------------+---------------+------+\n|        1|  15634602|Hargrave|        619|   France|Female| 42|     2|      0.0|            1|             1|      101348.88|     1|\n|        2|  15647311|    Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|             1|      112542.58|     0|\n|        3|  15619304|    Onio|        502|   France|Female| 42|     8| 159660.8|            3|             0|      113931.57|     1|\n|        4|  15701354|    Boni|        699|   France|Female| 39|     1|      0.0|            2|             0|       93826.63|     0|\n|        5|  15737888|Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|             1|        79084.1|     0|\n+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+--------------+---------------+------+\nonly showing top 5 rows\n\n+-------------+--------------------+----------+----------------+-------------+-----------+\n|   Account No| TRANSACTION DETAILS|VALUE DATE| WITHDRAWAL AMT | DEPOSIT AMT |BALANCE AMT|\n+-------------+--------------------+----------+----------------+-------------+-----------+\n|409000611074'|TRF FROM  Indiafo...| 29-Jun-17|            NULL|    1000000.0|  1000000.0|\n|409000611074'|TRF FROM  Indiafo...|  5-Jul-17|            NULL|    1000000.0|  2000000.0|\n|409000611074'|FDRL/INTERNAL FUN...| 18-Jul-17|            NULL|     500000.0|  2500000.0|\n|409000611074'|TRF FRM  Indiafor...|  1-Aug-17|            NULL|    3000000.0|  5500000.0|\n|409000611074'|FDRL/INTERNAL FUN...| 16-Aug-17|            NULL|     500000.0|  6000000.0|\n+-------------+--------------------+----------+----------------+-------------+-----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Loading Data\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Case Study\").getOrCreate()\n",
    "\n",
    "loan_file_path = \"/FileStore/tables/loan.csv\"\n",
    "credit_card_file_path = \"/FileStore/tables/credit_card.csv\"\n",
    "txn_file_path = \"/FileStore/tables/txn.csv\"\n",
    "\n",
    "loan_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(loan_file_path)\n",
    "\n",
    "credit_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(credit_card_file_path)\n",
    "\n",
    "txn_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(txn_file_path)\n",
    "\n",
    "# Display loaded DataFrames\n",
    "loan_df.show(5)  # Display first 5 rows of loan data\n",
    "credit_df.show(5)  # Display first 5 rows of credit card data\n",
    "txn_df.show(5)  # Display first 5 rows of transaction data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef7e3464-9645-4d30-bf12-5ac8ac2275e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n|     Loan Category|count|\n+------------------+-----+\n|           HOUSING|   67|\n|        TRAVELLING|   53|\n|       BOOK STORES|    7|\n|       AGRICULTURE|   12|\n|         GOLD LOAN|   77|\n|  EDUCATIONAL LOAN|   20|\n|        AUTOMOBILE|   60|\n|          BUSINESS|   24|\n|COMPUTER SOFTWARES|   35|\n|           DINNING|   14|\n|          SHOPPING|   35|\n|       RESTAURANTS|   41|\n|       ELECTRONICS|   14|\n|          BUILDING|    7|\n|        RESTAURANT|   20|\n|   HOME APPLIANCES|   14|\n+------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "#number of loans in each category\n",
    "loan_df.groupBy(\"Loan Category\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8e0c681-a0b0-457e-a9e1-552e383232f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people who have taken more than 1 lakh loan: 450\n"
     ]
    }
   ],
   "source": [
    "#Number of people who have taken more than 1 lakh loan\n",
    "\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "\n",
    "# First we Convert Loan Amount form String to Float\n",
    "loan_df_cleaned = loan_df.withColumn(\"Loan Amount\", regexp_replace(col(\"Loan Amount\"), \",\", \"\").cast(\"float\"))\n",
    "\n",
    "# Now, we use filter for people who have taken more than 1 lakh loan\n",
    "ans = loan_df_cleaned.filter(col(\"Loan Amount\") > 100000).count()\n",
    "\n",
    "print(f\"Number of people who have taken more than 1 lakh loan: {ans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9160fa42-7f4b-4820-8fd5-7f17d6be715a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of people with income greater than 60000 rupees: 198\n"
     ]
    }
   ],
   "source": [
    "#number of people with income greater than 60000 rupees\n",
    "\n",
    "ans=loan_df.filter(col(\"Income\") > 60000).count()\n",
    "print(f\"The Number of people with income greater than 60000 rupees: {ans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7670c29b-eb3e-4688-a6a6-99d8e16c9856",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of people with 2 or more returned cheques and income less than 50000: 137\n"
     ]
    }
   ],
   "source": [
    "# number of people with 2 or more returned cheques and income less than 50000\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "ans=loan_df.filter((col(\" Returned Cheque\") >= 2) & (col(\"Income\") < 50000)).count()\n",
    "print(f\"The Number of people with 2 or more returned cheques and income less than 50000: {ans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f46f7477-75ee-49f9-8433-e4fbfe3bb250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of people with 2 or more returned cheques and are single: 111\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# number of people with 2 or more returned cheques and are single\n",
    "ans=loan_df.filter((col(\" Returned Cheque\") >= 2) & (col(\"Marital Status\") == \"SINGLE\")).count()\n",
    "print(f\"The Number of people with 2 or more returned cheques and are single: {ans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77c108f7-7a5a-431b-b275-192179ecd7a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of people with expenditure over 50000 a month: 6\n"
     ]
    }
   ],
   "source": [
    "#number of people with expenditure over 50000 a month\n",
    "\n",
    "ans=loan_df.filter(col(\"Expenditure\") > 50000).count()\n",
    "print(f\"The number of people with expenditure over 50000 a month: {ans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aac8c45-64ee-4896-b5bb-3e7eaeb6c5a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Credit card users in Spain: 2477\n"
     ]
    }
   ],
   "source": [
    "#credit card users in Spain\n",
    "\n",
    "ans=credit_df.filter(col(\"Geography\") == \"Spain\").count()\n",
    "print(f\"Total Credit card users in Spain: {ans}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26d85d54-17a3-4883-abbb-0aa56daae64b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of members who are elgible and active in the bank: 5151\n"
     ]
    }
   ],
   "source": [
    "#number of members who are elgible and active in the bank\n",
    "\n",
    "ans=credit_df.filter((col(\"IsActiveMember\") == 1)).count()\n",
    "print(f\"The number of members who are elgible and active in the bank: {ans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10e3fdae-74f4-47f9-83a3-eef56dc9d337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum withdrawal amount in transactions: 459447546.4\n"
     ]
    }
   ],
   "source": [
    "#Maximum withdrawal amount in transactions\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "max_withdrawal = txn_df.select(max(col(\" WITHDRAWAL AMT \"))).collect()[0][0]\n",
    "print(f\"Maximum withdrawal amount in transactions: {max_withdrawal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f710fca7-d263-416f-b587-1f6115cb7218",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum withdrawal amount in transactions: 0.01\n"
     ]
    }
   ],
   "source": [
    "#MINIMUM WITHDRAWAL AMOUNT OF AN ACCOUNT in txn.csv\n",
    "from pyspark.sql.functions import min\n",
    "\n",
    "min_withdrawal = txn_df.select(min(col(\" WITHDRAWAL AMT \"))).collect()[0][0]\n",
    "print(f\"Minimum withdrawal amount in transactions: {min_withdrawal}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1632887-155e-41eb-afaf-1cf3dd66ca4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum deposit amount in transactions: 544800000.0\n"
     ]
    }
   ],
   "source": [
    "#MAXIMUM DEPOSIT AMOUNT OF AN ACCOUNT\n",
    "\n",
    "max_deposit = txn_df.select(max(col(\" DEPOSIT AMT \"))).collect()[0][0]\n",
    "print(f\"Maximum deposit amount in transactions: {max_deposit}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d1b63ad-8fc8-4cd5-b2f2-e14618f879c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum deposit amount in transactions: 0.01\n"
     ]
    }
   ],
   "source": [
    "#MINIMUM DEPOSIT AMOUNT OF AN ACCOUNT\n",
    "\n",
    "min_deposit = txn_df.select(min(col(\" DEPOSIT AMT \"))).collect()[0][0]\n",
    "print(f\"Minimum deposit amount in transactions: {min_deposit}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ef9bec-5335-4a10-9c0a-141d9d194248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions on each date:\n+----------+-----+\n|VALUE DATE|count|\n+----------+-----+\n| 23-Dec-16|  143|\n|  7-Feb-19|   98|\n| 21-Jul-15|   80|\n|  9-Sep-15|   91|\n| 17-Jan-15|   16|\n| 18-Nov-17|   53|\n| 21-Feb-18|   77|\n| 20-Mar-18|   71|\n| 19-Apr-18|   71|\n| 21-Jun-16|   97|\n| 17-Oct-17|  101|\n|  3-Jan-18|   70|\n|  8-Jun-18|  223|\n| 15-Dec-18|   62|\n|  8-Aug-16|   97|\n| 17-Dec-16|   74|\n|  3-Sep-15|   83|\n| 21-Jan-16|   76|\n|  4-May-18|   92|\n|  7-Sep-17|   94|\n+----------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Number of transaction on each date\n",
    "\n",
    "print(\"Number of transactions on each date:\")\n",
    "txn_count_by_date = txn_df.groupBy(\"VALUE DATE\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd022de-48ea-4abf-95d9-24c131360792",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of customers with withdrawal amount more than 1 lakh:\n+-------------+\n|   Account No|\n+-------------+\n|409000438611'|\n|     1196711'|\n|     1196428'|\n|409000493210'|\n|409000611074'|\n|409000425051'|\n|409000405747'|\n|409000493201'|\n|409000438620'|\n|409000362497'|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "#List of customers with withdrawal amount more than 1 lakh\n",
    "\n",
    "print(\"List of customers with withdrawal amount more than 1 lakh:\")\n",
    "customers_with_high_withdrawals = txn_df.filter(col(\" WITHDRAWAL AMT \") > 100000).select(\"Account No\").distinct().show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySpark Case Study 3 Aathirainathan P",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
